{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import pywt\n",
    "import scipy.signal\n",
    "import scipy.ndimage\n",
    "import ecg\n",
    "import tqdm\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guohuan = pd.read_csv(r'D:\\\\byx\\\\baseline\\\\myEcg\\\\data\\\\过缓.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,age in zip(guohuan['index'],guohuan['age']):\n",
    "    print(index,age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP,FN = 0,0\n",
    "error = []\n",
    "for txtname,age in zip(guohuan['index'],guohuan['age']):\n",
    "    df = pd.read_csv(r'D:\\\\byx\\\\baseline\\\\myEcg\\\\data\\\\hf_round2_train\\\\%s'%txtname,delimiter=' ')\n",
    "    sampling_rate = 500\n",
    "    if ecg.raise_error(df['I']):\n",
    "        print('error',txtname)\n",
    "        continue\n",
    "    #peaks = R_peak(df,plot=False)\n",
    "    _,_,epochs = ecg.segment(df,plot=False)\n",
    "    #print((np.mean(r['T_Onsets']) - np.mean(r['P_Offsets'])) / 500)\n",
    "    #print('心率：',60 / len(epochs[0]) * sampling_rate)\n",
    "    xinlv = 60 / len(epochs[0]) * sampling_rate\n",
    "    if xinlv > 60:\n",
    "        #print(txtname)\n",
    "        #peaks = ecg.R_peak(df,plot=True)\n",
    "        #error.append(txtname)\n",
    "        FN += 1\n",
    "    else:\n",
    "        TP += 1\n",
    "print(TP/(TP+FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP,TN = 0,0\n",
    "trains = glob.glob(r'D:\\\\byx\\\\baseline\\\\myEcg\\\\data\\\\hf_round2_train\\\\**.txt')\n",
    "c = 0\n",
    "for txtname in tqdm.tqdm(trains[:100]):\n",
    "    txtn = txtname.split('\\\\')[-1]\n",
    "    if txtn not in guohuan['index']:\n",
    "        df = pd.read_csv(txtname,delimiter=' ')\n",
    "        if ecg.raise_error(df['I']):\n",
    "            print('error',txtname)\n",
    "            continue\n",
    "        _,_,epochs,_ = ecg.segment(df,plot=False)\n",
    "        xinlv = 60 / len(epochs[0]) * sampling_rate\n",
    "        if xinlv > 60:\n",
    "            #print(txtname)\n",
    "            #peaks = ecg.R_peak(df,plot=True)\n",
    "            #error.append(txtname)\n",
    "            TN += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "            peaks = ecg.R_peak(df,plot=True)\n",
    "            print(xinlv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "F1 = 2 * (Precision*Recall)/(Precision+Recall)\n",
    "Accuracy = (TP+TN) / (TP+FP+FN+TN)\n",
    "print(f'Precision = {Precision}')\n",
    "print(f'Recall = {Recall}')\n",
    "print(f'F1 = {F1}')\n",
    "print(f'Accuracy = {Accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heart_rating(txtname,sampling_rate=500):\n",
    "    df = pd.read_csv(r'D:\\\\byx\\\\baseline\\\\myEcg\\\\data\\\\hf_round2_train\\\\%s'%txtname,delimiter=' ')\n",
    "    if ecg.raise_error(df['I']):\n",
    "        print('error',txtname)\n",
    "        return np.nan\n",
    "    _,_,epochs,_ = ecg.segment(df,plot=False)\n",
    "    xinlv = 60 / len(epochs[0]) * sampling_rate\n",
    "    return xinlv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "root = 'D:\\\\byx\\\\baseline\\\\myEcg\\\\data'\n",
    "train_csv = os.path.join(root,'hf_round2_label_train.csv')\n",
    "train = pd.read_csv(train_csv)\n",
    "train = train.dropna(axis=0,how='any')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['one_label'] = train['one_label'].map(lambda x: eval(x))\n",
    "train['guohuan'] = train['one_label'].map(lambda x:1 if x[18]==1.0 else 0)\n",
    "train['heart_ratings'] = train['index'].map(lambda x:heart_rating(x))\n",
    "train = train.dropna(axis=0,how='any')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sex2'] = train['sex'].map(lambda x:1 if x=='MALE' else 0)\n",
    "train_size = int(len(train)*0.5)\n",
    "train_dataset = train[:train_size]\n",
    "test_dataset = train[train_size:]\n",
    "X_train = train_dataset[['age','heart_ratings','sex2']]\n",
    "y_train = train_dataset['guohuan']\n",
    "X_test = test_dataset[['age','heart_ratings','sex2']]\n",
    "y_test = test_dataset['guohuan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_heartrating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pre = clf.predict(X_test)\n",
    "recall = recall_score(y_test,y_pre)\n",
    "accuracy = accuracy_score(y_test,y_pre)\n",
    "precision = precision_score(y_test,y_pre)\n",
    "F1 = f1_score(y_test,y_pre)\n",
    "print(f'Precision = {precision}')\n",
    "print(f'*Recall* = {recall}')\n",
    "print(f'F1 = {F1}')\n",
    "print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['guohuan']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_,clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['guosu'] = train['one_label'].map(lambda x:1 if x[30]==1.0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_size = int(len(train)*0.5)\n",
    "train_dataset = train[:train_size]\n",
    "test_dataset = train[train_size:]\n",
    "X_train = train_dataset[['age','heart_ratings']]\n",
    "y_train = train_dataset['guosu']\n",
    "X_test = test_dataset[['age','heart_ratings']]\n",
    "y_test = test_dataset['guosu']\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pre = clf.predict(X_test)\n",
    "recall = recall_score(y_test,y_pre)\n",
    "accuracy = accuracy_score(y_test,y_pre)\n",
    "precision = precision_score(y_test,y_pre)\n",
    "F1 = f1_score(y_test,y_pre)\n",
    "print(f'Precision = {precision}')\n",
    "print(f'*Recall* = {recall}')\n",
    "print(f'F1 = {F1}')\n",
    "print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过速 - 东阳数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heart_rating(txtname,sampling_rate=500):\n",
    "    df = pd.read_csv(r'D:\\\\byx\\\\Dongyang\\\\txt_data\\\\%s'%txtname,delimiter=' ')\n",
    "    if ecg.raise_error(df['I']) or ecg.raise_error(df['II']):\n",
    "        print('error',txtname)\n",
    "        return np.nan\n",
    "    try:\n",
    "        peaks = ecg.R_peak(df,lead='II')\n",
    "        xinlv = 60/((peaks[-1]-peaks[0])/(len(peaks)-1)/500)\n",
    "    except Exception as e:\n",
    "        print('***',txtname)\n",
    "        return np.nan\n",
    "    return xinlv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error FILE@1e0b8bbcdef629bcbd9c9b2a1ec089fe.txt\n",
      "error FILE@4f1a221eb1c6dfb2c60cc1cde87d4e14.txt\n",
      "error FILE@d15c379778cf7350a4a176d5808d8610.txt\n",
      "error FILE@e737727ffd67ec307c9e3215c58363a2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error FILE@ad05a8eae444a886d170e0afe625e220.txt\n",
      "*** FILE@3fad165d7f5d570245b99c0404f06320.txt\n",
      "error FILE@bdd1c1b39973d2acbc5e6369002aa41a.txt\n",
      "error FILE@23c8361eb7b9ab521a1a426fca418653.txt\n",
      "var 0.868702916605499\n",
      "error FILE@155676cebef1303fce8d38e997490d8b.txt\n",
      "error FILE@4b250ee5e9354bc2bd7d3cbcc5ad6baf.txt\n",
      "error FILE@0c0f9b0f9d64edbe45a41b68fbc4eb48.txt\n",
      "*** FILE@e17105813b0b68f28f9302b1084ef27f.txt\n",
      "error FILE@ebaacace99c24fe98b37706b46e6bf06.txt\n",
      "error FILE@20307972eb1ce087834b3b22cafb13fd.txt\n",
      "error FILE@0f0b2b8a774ad53eede2d153a1b8b8b4.txt\n",
      "error FILE@121495d6143ee2b243d4411f4b580e1c.txt\n",
      "*** FILE@0c1f0f410a784f2d827237925e50613d.txt\n",
      "error FILE@8c3ae29d1b4094b3179f0166be65104c.txt\n",
      "error FILE@0a50273cf10b9aed5362e3bfdc1a63f4.txt\n",
      "var 0.9402701742497822\n",
      "error FILE@2edb24ef539f1764818fa3e704b50ede.txt\n",
      "error FILE@b053cc4414c5b20f59f33c9ce0828a2b.txt\n",
      "error FILE@87988a6ceed5bedf2afbc61af3479ca8.txt\n",
      "error FILE@a0661d50fd9b9fc485288763a7178f0c.txt\n",
      "error FILE@ae0d004424de6acc8f344ab1ab252629.txt\n",
      "*** FILE@7e357f0fefea7da2336818e410619304.txt\n",
      "error FILE@aba381f323cdb27899e97921af5342da.txt\n",
      "error FILE@bcbc79d6e2d440fc87131674205cd09b.txt\n",
      "error FILE@674c1bf6752e639e0a7af59a3ce461bf.txt\n",
      "var 0.4500392982138304\n",
      "error FILE@9c756182d7fd5abf87e2df88aca5837b.txt\n",
      "var 0.43354477847024175\n",
      "error FILE@288d5e67ffa72697e79f29dcb9e94ce6.txt\n",
      "error FILE@18ca61ce1b8501ab90333191e169a8f6.txt\n",
      "error FILE@fce551b6238eeb2d4a3eb090eb4ae910.txt\n",
      "error FILE@09ffc7ff78d330d90ba26e727b53ef13.txt\n",
      "*** FILE@c8915a50c374f841b683f5738424090f.txt\n",
      "var 0.5903129628000561\n",
      "error FILE@35e7a245fae23e81526323fe8aff9da5.txt\n",
      "error FILE@53643c30334cc3e332c40715bf4c6dfc.txt\n",
      "error FILE@8919300f2dad3e1360f5397649f80453.txt\n",
      "error FILE@01bc109860e7e2adbafc7813bdd84644.txt\n",
      "error FILE@9145f472ab75f03527e98eefc431c816.txt\n",
      "error FILE@7cb2d85c8fa8f46e2e60255980034297.txt\n",
      "error FILE@179d4ce5a970e79fc4b5ebbd23d904bb.txt\n",
      "error FILE@76b214deeafd7dcea5880798e3cf4767.txt\n",
      "*** FILE@a2eb6023e2ded2574db33b91961aab4e.txt\n",
      "var 0.7537783532881868\n",
      "error FILE@02f89ae991754610c3b7a75a9257b016.txt\n",
      "error FILE@e9117655227ee9ad5cf64ddcdc376b24.txt\n",
      "error FILE@faf77de38d81976ee291e63d0198d934.txt\n",
      "error FILE@4d76f01e408528ec077cac157a86cf00.txt\n",
      "error FILE@2ac6d63b2ebe6c5f5bc8ef6b8b7641af.txt\n",
      "error FILE@70224624d84c1cc7ef2ae74a8c53ff02.txt\n",
      "*** FILE@513b362ea18a2662ce70a4c4198710d1.txt\n",
      "error FILE@1a7ae8fb7408c2af6f0e65766f3eb730.txt\n",
      "error FILE@532fa1ae7ce46a15b8c282663c508d8a.txt\n",
      "error FILE@c2d398b8dfa601ca292d95ebe0e3ba3e.txt\n",
      "error FILE@273c8049daace6726bba49a8de200bb9.txt\n",
      "error FILE@e9306a4d6629ac051b743ca9c7e0627b.txt\n",
      "error FILE@67874ca40a504e8a85a6b35ca64388a6.txt\n",
      "error FILE@08ca4bd452006c9e35163bee4816f9b0.txt\n",
      "error FILE@c7006cf20befa941618f129a0b084bb0.txt\n",
      "error FILE@488f7aebf8ad5389c01016af23f22ebc.txt\n",
      "error FILE@b2685213ad86a875defb1d0c3e4acf35.txt\n",
      "error FILE@7253f405b1f047508187a8de1d42b54d.txt\n",
      "error FILE@14338d91cee475544bed85aef8c6cba0.txt\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(r'D:\\byx\\Dongyang\\label_add_heartrating_2.csv')\n",
    "train['heart_rating_updated'] = train['0'].map(lambda x:heart_rating(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(axis=0,how='any')  \n",
    "train_size = int(len(train)*0.5)\n",
    "train_dataset = train[:train_size]\n",
    "test_dataset = train[train_size:]\n",
    "X_train = train_dataset[['heart_rating']]\n",
    "y_train = train_dataset['过缓']\n",
    "X_test = test_dataset[['heart_rating']]\n",
    "y_test = test_dataset['过缓']\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pre = clf.predict(X_test)\n",
    "recall = recall_score(y_test,y_pre)\n",
    "accuracy = accuracy_score(y_test,y_pre)\n",
    "precision = precision_score(y_test,y_pre)\n",
    "F1 = f1_score(y_test,y_pre)\n",
    "print(f'Precision = {precision}')\n",
    "print(f'*Recall* = {recall}')\n",
    "print(f'F1 = {F1}')\n",
    "print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = train['heart_rating'].map(lambda x:1 if x < 60 else 0)\n",
    "y_test = train['过缓']\n",
    "recall = recall_score(y_test,y_pre)\n",
    "accuracy = accuracy_score(y_test,y_pre)\n",
    "precision = precision_score(y_test,y_pre)\n",
    "F1 = f1_score(y_test,y_pre)\n",
    "print(f'Precision = {precision}')\n",
    "print(f'*Recall* = {recall}')\n",
    "print(f'F1 = {F1}')\n",
    "print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['过缓']==1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
